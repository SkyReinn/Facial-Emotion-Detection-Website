# -*- coding: utf-8 -*-
"""Transfer_Learning_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/113IvPPtU83hIyaWmp8koEm8sxRuq8g-B
"""

#import libraries
import re
import cv2
import dlib
import keras
import pickle
import warnings
import itertools 
import numpy as np
import pandas as pd
import urllib.request
import seaborn as sns
import tensorflow as tf
from sklearn import metrics
from keras import optimizers
from keras.regularizers import l2
from tqdm import tqdm,tqdm_pandas
from scipy.spatial import distance
from keras.models import Sequential
from keras.models import load_model
from matplotlib import pyplot as plt
from sklearn.metrics import accuracy_score
from keras.applications.vgg16 import VGG16
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam, SGD
from keras.losses import categorical_crossentropy
from sklearn.model_selection import train_test_split
from keras.wrappers.scikit_learn import KerasClassifier
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization
from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D

#download data
!wget -q --show-progress "https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/fer2013_5.csv"
!wget -q --show-progress "https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/shape_predictor_68_face_landmarks.dat"
!wget -q --show-progress "https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/pureX.npy"
!wget -q --show-progress -O ./dataX.npy "https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/dataX_edited.npy"
!wget -q --show-progress "https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/dataY.npy"

#define hyperparameters
epochs = 20
n_labels = 5 
batch_size = 64
test_ratio = .1
width, height = 48, 48

#load data 
dataX_pixels = np.load('pureX.npy')
dataY_labels = np.load('dataY.npy')

#convert labels to one hot encoding
y_onehot = to_categorical(dataY_labels, len(set(dataY_labels)))

#split data into train and test
X_train, X_test, y_train, y_test = train_test_split(dataX_pixels, y_onehot, test_size=test_ratio, random_state=42)

#stadardize the data
pixel_scaler = StandardScaler()
pixel_scaler.fit(X_train)
X_train = pixel_scaler.transform(X_train)
X_test = pixel_scaler.transform(X_test)

#reshape the data and add another dimension for model compatibility
X_train_cnn = X_train.reshape(len(X_train),height,width)
X_test_cnn = X_test.reshape(len(X_test),height,width)
X_train_cnn = np.expand_dims(X_train_cnn,3)
X_test_cnn = np.expand_dims(X_test_cnn,3)
print(X_train_cnn.shape)

#load VGG16 for transfer learning
vgg_expert = VGG16(weights = 'imagenet', include_top = False, input_shape = (48, 48, 3))

#add the first 12 layers of VGG16
vgg_model = Sequential()
vgg_model.add(vgg_expert)

#add additional layers for output
vgg_model.add(Flatten())
vgg_model.add(Dense(512, activation = 'relu'))
vgg_model.add(Dropout(0.5))
vgg_model.add(Dense(5, activation = 'softmax'))

#build the model
vgg_model.compile(loss = 'categorical_crossentropy', optimizer = SGD(lr=1e-4, momentum=0.95), metrics=['accuracy'])

#model summary
vgg_model.summary()

#reshape data to fit transfer learning model
X_TRAIN = np.array([np.transpose(np.array([X_train_cnn[ix].squeeze() for i in range(3)]), (1,2,0)) for ix in range(len(X_train))])
X_TEST = np.array([np.transpose(np.array([X_test_cnn[ix].squeeze() for i in range(3)]), (1,2,0)) for ix in range(len(X_test))])

#train the model
vgg_history = vgg_model.fit(X_TRAIN, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_TEST, y_test), shuffle=True)

#evaluate the model
vgg_performance = vgg_model.evaluate(X_TEST, y_test, batch_size=64)

#download model as zip file to drive
from google.colab import drive
drive.mount('/content/gdrive')
save_path = F"/content/gdrive/My Drive/vgg.zip" 

tf.keras.models.save_model(vgg_model,'vgg')
import zipfile

import os
import zipfile

def zipdir(path, ziph):
    for root, dirs, files in os.walk(path):
        for file in files:
            ziph.write(os.path.join(root, file))


zipf = zipfile.ZipFile(save_path, 'w', zipfile.ZIP_DEFLATED)
zipdir('vgg', zipf)
zipf.close()